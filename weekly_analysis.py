#!/usr/bin/env python3
"""
æ¯å‘¨åˆ†æå’Œæ¨¡å‹ä¼˜åŒ–æ¨¡å—
- åˆ†æè¿‡å»ä¸€å‘¨çš„ç­›é€‰å‡†ç¡®æ€§
- æ£€æµ‹è¿‡æ‹Ÿåˆé—®é¢˜
- è‡ªåŠ¨è°ƒæ•´æ¨¡å‹å‚æ•°
- ç”Ÿæˆåˆ†ææŠ¥å‘Šå¹¶å‘é€Telegramé€šçŸ¥
"""

import sys
sys.path.append('/opt/.manus/.sandbox-runtime')

import json
import smtplib
import requests
import logging
import statistics
from datetime import datetime, timedelta
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from collections import defaultdict

from data_store import DataStore, PerformanceTracker

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class TelegramNotifier:
    """Telegramé€šçŸ¥ç±»"""
    
    def __init__(self, bot_token: str, chat_id: str):
        self.bot_token = bot_token
        self.chat_id = chat_id
    
    def send_message(self, text: str, parse_mode: str = 'HTML') -> bool:
        """å‘é€Telegramæ¶ˆæ¯"""
        try:
            max_length = 4000
            messages = [text[i:i+max_length] for i in range(0, len(text), max_length)]
            
            for msg in messages:
                response = requests.post(
                    f"https://api.telegram.org/bot{self.bot_token}/sendMessage",
                    json={
                        'chat_id': self.chat_id,
                        'text': msg,
                        'parse_mode': parse_mode
                    }
                )
                if response.status_code != 200:
                    logger.error(f"Telegramå‘é€å¤±è´¥: {response.text}")
                    return False
            
            logger.info("Telegramæ¶ˆæ¯å‘é€æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"Telegramå‘é€å¼‚å¸¸: {e}")
            return False


class WeeklyAnalyzer:
    """æ¯å‘¨åˆ†æå™¨"""
    
    def __init__(self, config_path: str = '/home/ubuntu/stock_screener/config.json'):
        self.store = DataStore()
        self.tracker = PerformanceTracker()
        self.config = self._load_config(config_path)
        self.config_path = config_path
    
    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®"""
        try:
            with open(config_path, 'r') as f:
                return json.load(f)
        except:
            return {}
    
    def _save_config(self):
        """ä¿å­˜é…ç½®"""
        with open(self.config_path, 'w') as f:
            json.dump(self.config, f, indent=2, ensure_ascii=False)
    
    def update_tracking_data(self):
        """æ›´æ–°æ‰€æœ‰è¿½è¸ªæ•°æ®"""
        logger.info("å¼€å§‹æ›´æ–°è¿½è¸ªæ•°æ®...")
        self.tracker.update_all_tracking()
        logger.info("è¿½è¸ªæ•°æ®æ›´æ–°å®Œæˆ")
    
    def analyze_week(self, week_end: datetime.date = None) -> Dict:
        """åˆ†æä¸€å‘¨çš„è¡¨ç°"""
        week_end = week_end or datetime.now().date()
        week_start = week_end - timedelta(days=7)
        
        logger.info(f"åˆ†æå‘¨æœŸ: {week_start} è‡³ {week_end}")
        
        # è·å–ç»Ÿè®¡æ•°æ®
        stats = self.store.get_tracking_stats(days=14)
        
        # è·å–æœ¬å‘¨çš„è¯¦ç»†æ•°æ®
        results = self.store.get_results_by_date_range(week_start, week_end)
        
        # åˆ†æå„ç±»ä¿¡å·çš„è¡¨ç°
        signal_performance = self._analyze_signal_performance(week_start, week_end)
        
        # æ£€æµ‹è¿‡æ‹Ÿåˆ
        overfitting_analysis = self._detect_overfitting(stats)
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        optimization_suggestions = self._generate_optimization_suggestions(
            stats, signal_performance, overfitting_analysis
        )
        
        # æ±‡æ€»åˆ†æç»“æœ
        analysis = {
            'week_start': week_start.isoformat(),
            'week_end': week_end.isoformat(),
            'total_signals': stats['total_signals'],
            'successful_signals': stats['successful_signals'],
            'accuracy_rate': stats['accuracy_rate'],
            'avg_return': stats['avg_return'],
            'avg_max_gain': stats['avg_max_gain'],
            'avg_max_loss': stats['avg_max_loss'],
            'by_score': stats['by_score'],
            'signal_performance': signal_performance,
            'overfitting_analysis': overfitting_analysis,
            'optimization_suggestions': optimization_suggestions,
            'best_performer': self._find_best_performer(week_start, week_end),
            'worst_performer': self._find_worst_performer(week_start, week_end)
        }
        
        # ä¿å­˜åˆ†æç»“æœ
        self.store.save_weekly_analysis(analysis)
        
        return analysis
    
    def _analyze_signal_performance(self, week_start: datetime.date, week_end: datetime.date) -> Dict:
        """åˆ†æå„ç±»ä¿¡å·çš„è¡¨ç°"""
        import sqlite3
        conn = sqlite3.connect(self.store.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT sr.signals, pt.day7_change, pt.is_successful, sr.score
            FROM screening_results sr
            JOIN performance_tracking pt ON sr.id = pt.screening_id
            WHERE DATE(sr.scan_time) BETWEEN ? AND ?
            AND pt.day7_change IS NOT NULL
        ''', (week_start.isoformat(), week_end.isoformat()))
        
        signal_stats = defaultdict(lambda: {'count': 0, 'successful': 0, 'returns': []})
        
        for row in cursor.fetchall():
            signals = json.loads(row[0]) if row[0] else []
            day7_change = row[1]
            is_successful = row[2]
            
            for signal in signals:
                signal_type = self._extract_signal_type(signal)
                signal_stats[signal_type]['count'] += 1
                if is_successful:
                    signal_stats[signal_type]['successful'] += 1
                signal_stats[signal_type]['returns'].append(day7_change)
        
        conn.close()
        
        performance = {}
        for signal_type, data in signal_stats.items():
            if data['count'] > 0:
                performance[signal_type] = {
                    'count': data['count'],
                    'accuracy': (data['successful'] / data['count']) * 100,
                    'avg_return': statistics.mean(data['returns']) if data['returns'] else 0,
                    'std_return': statistics.stdev(data['returns']) if len(data['returns']) > 1 else 0
                }
        
        return performance
    
    def _extract_signal_type(self, signal: str) -> str:
        """ä»ä¿¡å·æ–‡æœ¬ä¸­æå–ç±»å‹"""
        if 'MA' in signal and 'é‡‘å‰' in signal:
            return 'MAé‡‘å‰'
        elif 'MACD' in signal and 'é‡‘å‰' in signal:
            return 'MACDé‡‘å‰'
        elif 'MACD' in signal and 'å¤šå¤´' in signal:
            return 'MACDå¤šå¤´'
        elif 'RSI' in signal and 'åå¼¹' in signal:
            return 'RSIåå¼¹'
        elif 'RSI' in signal and 'å¥åº·' in signal:
            return 'RSIå¥åº·'
        elif 'æˆäº¤é‡' in signal and 'æ”¾å¤§' in signal:
            return 'æˆäº¤é‡æ”¾å¤§'
        elif '52å‘¨' in signal or 'æ–°é«˜' in signal:
            return 'æ¥è¿‘æ–°é«˜'
        elif 'çªç ´' in signal:
            return 'ä»·æ ¼çªç ´'
        elif 'OBV' in signal:
            return 'OBVç¡®è®¤'
        else:
            return 'å…¶ä»–'
    
    def _detect_overfitting(self, stats: Dict) -> Dict:
        """æ£€æµ‹è¿‡æ‹Ÿåˆ"""
        analysis = {
            'is_overfitting': False,
            'concerns': [],
            'severity': 'low'
        }
        
        by_score = stats.get('by_score', {})
        
        high_acc = by_score.get('high', {}).get('accuracy', 0)
        low_acc = by_score.get('low', {}).get('accuracy', 0)
        
        if high_acc > 0 and low_acc > 0:
            if high_acc < low_acc + 10:
                analysis['concerns'].append("é«˜åˆ†è‚¡ç¥¨å‡†ç¡®ç‡æœªæ˜¾è‘—é«˜äºä½åˆ†ï¼Œè¯„åˆ†ç³»ç»Ÿå¯èƒ½éœ€è¦è°ƒæ•´")
                analysis['is_overfitting'] = True
        
        overall_acc = stats.get('accuracy_rate', 0)
        if overall_acc > 80:
            analysis['concerns'].append(f"å‡†ç¡®ç‡è¿‡é«˜ ({overall_acc:.1f}%)ï¼Œå¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆæˆ–æ ·æœ¬åå·®")
            analysis['is_overfitting'] = True
            analysis['severity'] = 'medium'
        elif overall_acc < 30:
            analysis['concerns'].append(f"å‡†ç¡®ç‡è¿‡ä½ ({overall_acc:.1f}%)ï¼Œæ¨¡å‹éœ€è¦é‡æ–°æ ¡å‡†")
            analysis['severity'] = 'high'
        
        avg_return = stats.get('avg_return', 0)
        avg_max_loss = stats.get('avg_max_loss', 0)
        
        if avg_max_loss < -10 and avg_return < 3:
            analysis['concerns'].append(f"é£é™©æ”¶ç›Šæ¯”ä¸ä½³: å¹³å‡æ”¶ç›Š {avg_return:.1f}%, å¹³å‡æœ€å¤§äºæŸ {avg_max_loss:.1f}%")
            analysis['severity'] = 'medium'
        
        total = stats.get('total_signals', 0)
        if total < 20:
            analysis['concerns'].append(f"æ ·æœ¬é‡ä¸è¶³ ({total}ä¸ª)ï¼Œåˆ†æç»“æœå¯èƒ½ä¸å¯é ")
        
        return analysis
    
    def _generate_optimization_suggestions(self, stats: Dict, signal_perf: Dict, overfitting: Dict) -> List[Dict]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []
        
        for signal_type, perf in signal_perf.items():
            if perf['count'] >= 5:
                if perf['accuracy'] < 30:
                    suggestions.append({
                        'type': 'reduce_weight',
                        'target': signal_type,
                        'reason': f"å‡†ç¡®ç‡è¿‡ä½ ({perf['accuracy']:.1f}%)",
                        'action': f"å»ºè®®é™ä½ {signal_type} çš„æƒé‡",
                        'priority': 'high'
                    })
                elif perf['accuracy'] > 70 and perf['avg_return'] > 5:
                    suggestions.append({
                        'type': 'increase_weight',
                        'target': signal_type,
                        'reason': f"è¡¨ç°ä¼˜å¼‚: å‡†ç¡®ç‡ {perf['accuracy']:.1f}%, å¹³å‡æ”¶ç›Š {perf['avg_return']:.1f}%",
                        'action': f"å»ºè®®æé«˜ {signal_type} çš„æƒé‡",
                        'priority': 'medium'
                    })
        
        by_score = stats.get('by_score', {})
        high_perf = by_score.get('high', {})
        
        if high_perf.get('accuracy', 0) < 50:
            suggestions.append({
                'type': 'adjust_threshold',
                'target': 'high_score_threshold',
                'reason': f"é«˜åˆ†è‚¡ç¥¨å‡†ç¡®ç‡ä¸è¶³ ({high_perf.get('accuracy', 0):.1f}%)",
                'action': "å»ºè®®æé«˜é«˜åˆ†é˜ˆå€¼æˆ–è°ƒæ•´è¯„åˆ†æƒé‡",
                'priority': 'high'
            })
        
        if overfitting['is_overfitting']:
            for concern in overfitting['concerns']:
                suggestions.append({
                    'type': 'review',
                    'target': 'model',
                    'reason': concern,
                    'action': "éœ€è¦äººå·¥å®¡æŸ¥æ¨¡å‹å‚æ•°",
                    'priority': overfitting['severity']
                })
        
        return suggestions
    
    def _find_best_performer(self, week_start: datetime.date, week_end: datetime.date) -> Optional[Dict]:
        """æ‰¾å‡ºè¡¨ç°æœ€å¥½çš„è‚¡ç¥¨"""
        import sqlite3
        conn = sqlite3.connect(self.store.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT sr.symbol, sr.name, sr.price as signal_price, sr.score,
                   pt.day7_change, pt.max_gain
            FROM screening_results sr
            JOIN performance_tracking pt ON sr.id = pt.screening_id
            WHERE DATE(sr.scan_time) BETWEEN ? AND ?
            AND pt.day7_change IS NOT NULL
            ORDER BY pt.day7_change DESC
            LIMIT 1
        ''', (week_start.isoformat(), week_end.isoformat()))
        
        row = cursor.fetchone()
        conn.close()
        
        if row:
            return {
                'symbol': row[0],
                'name': row[1],
                'signal_price': row[2],
                'score': row[3],
                'day7_change': row[4],
                'max_gain': row[5]
            }
        return None
    
    def _find_worst_performer(self, week_start: datetime.date, week_end: datetime.date) -> Optional[Dict]:
        """æ‰¾å‡ºè¡¨ç°æœ€å·®çš„è‚¡ç¥¨"""
        import sqlite3
        conn = sqlite3.connect(self.store.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT sr.symbol, sr.name, sr.price as signal_price, sr.score,
                   pt.day7_change, pt.max_loss
            FROM screening_results sr
            JOIN performance_tracking pt ON sr.id = pt.screening_id
            WHERE DATE(sr.scan_time) BETWEEN ? AND ?
            AND pt.day7_change IS NOT NULL
            ORDER BY pt.day7_change ASC
            LIMIT 1
        ''', (week_start.isoformat(), week_end.isoformat()))
        
        row = cursor.fetchone()
        conn.close()
        
        if row:
            return {
                'symbol': row[0],
                'name': row[1],
                'signal_price': row[2],
                'score': row[3],
                'day7_change': row[4],
                'max_loss': row[5]
            }
        return None
    
    def auto_optimize_model(self, analysis: Dict) -> Dict:
        """è‡ªåŠ¨ä¼˜åŒ–æ¨¡å‹å‚æ•°"""
        suggestions = analysis.get('optimization_suggestions', [])
        adjustments = {'applied': [], 'skipped': []}
        
        current_weights = self.config.get('weights', {
            'ma_golden_cross': 25,
            'macd_golden_cross': 20,
            'rsi_bullish': 15,
            'volume_surge': 15,
            'price_breakout': 15,
            'obv_confirm': 10
        })
        
        signal_to_weight = {
            'MAé‡‘å‰': 'ma_golden_cross',
            'MACDé‡‘å‰': 'macd_golden_cross',
            'MACDå¤šå¤´': 'macd_golden_cross',
            'RSIåå¼¹': 'rsi_bullish',
            'RSIå¥åº·': 'rsi_bullish',
            'æˆäº¤é‡æ”¾å¤§': 'volume_surge',
            'æ¥è¿‘æ–°é«˜': 'price_breakout',
            'ä»·æ ¼çªç ´': 'price_breakout',
            'OBVç¡®è®¤': 'obv_confirm'
        }
        
        new_weights = current_weights.copy()
        
        for suggestion in suggestions:
            if suggestion['type'] == 'reduce_weight':
                weight_key = signal_to_weight.get(suggestion['target'])
                if weight_key and weight_key in new_weights:
                    old_value = new_weights[weight_key]
                    new_value = max(5, old_value - 5)
                    new_weights[weight_key] = new_value
                    adjustments['applied'].append({
                        'param': weight_key,
                        'old': old_value,
                        'new': new_value,
                        'reason': suggestion['reason']
                    })
            
            elif suggestion['type'] == 'increase_weight':
                weight_key = signal_to_weight.get(suggestion['target'])
                if weight_key and weight_key in new_weights:
                    old_value = new_weights[weight_key]
                    new_value = min(35, old_value + 5)
                    new_weights[weight_key] = new_value
                    adjustments['applied'].append({
                        'param': weight_key,
                        'old': old_value,
                        'new': new_value,
                        'reason': suggestion['reason']
                    })
            
            elif suggestion['type'] == 'review':
                adjustments['skipped'].append({
                    'suggestion': suggestion['action'],
                    'reason': 'éœ€è¦äººå·¥å®¡æŸ¥'
                })
        
        if adjustments['applied']:
            self.config['weights'] = new_weights
            self._save_config()
            
            self.store.save_model_params(
                new_weights,
                analysis.get('accuracy_rate'),
                f"è‡ªåŠ¨ä¼˜åŒ–: {len(adjustments['applied'])} é¡¹è°ƒæ•´"
            )
            
            logger.info(f"æ¨¡å‹å‚æ•°å·²æ›´æ–°: {len(adjustments['applied'])} é¡¹è°ƒæ•´")
        
        return adjustments
    
    def format_telegram_message(self, analysis: Dict, adjustments: Dict = None) -> str:
        """ç”ŸæˆTelegramæ ¼å¼æ¶ˆæ¯"""
        accuracy = analysis.get('accuracy_rate', 0)
        status_icon = "âœ…" if accuracy >= 50 else ("âš ï¸" if accuracy >= 30 else "ğŸ”´")
        
        lines = [
            f"ğŸ“ˆ <b>æ¯å‘¨åˆ†ææŠ¥å‘Š</b>",
            f"ğŸ“… {analysis['week_start']} ~ {analysis['week_end']}",
            "",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
            "<b>ğŸ“Š æ•´ä½“è¡¨ç°</b>",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
            f"æ€»ä¿¡å·æ•°: <b>{analysis['total_signals']}</b>",
            f"æˆåŠŸä¿¡å·: <b>{analysis['successful_signals']}</b>",
            f"å‡†ç¡®ç‡: {status_icon} <b>{accuracy:.1f}%</b>",
            f"å¹³å‡æ”¶ç›Š: <b>{analysis['avg_return']:.2f}%</b>",
            f"å¹³å‡æœ€å¤§æ¶¨å¹…: <b>{analysis['avg_max_gain']:.2f}%</b>",
            f"å¹³å‡æœ€å¤§è·Œå¹…: <b>{analysis['avg_max_loss']:.2f}%</b>",
            "",
        ]
        
        # æŒ‰è¯„åˆ†åˆ†ç»„
        by_score = analysis.get('by_score', {})
        if by_score:
            lines.append("<b>ğŸ“ˆ æŒ‰è¯„åˆ†åˆ†ç»„</b>")
            for group, data in by_score.items():
                group_name = {'high': 'é«˜åˆ†(â‰¥70)', 'medium': 'ä¸­åˆ†(40-69)', 'low': 'ä½åˆ†(<40)'}.get(group, group)
                lines.append(f"  {group_name}: {data['total']}ä¸ª, å‡†ç¡®ç‡ {data['accuracy']:.1f}%")
            lines.append("")
        
        # æœ€ä½³/æœ€å·®è¡¨ç°
        best = analysis.get('best_performer')
        worst = analysis.get('worst_performer')
        if best:
            lines.append(f"ğŸ† <b>æœ€ä½³</b>: {best['symbol']} +{best['day7_change']:.1f}%")
        if worst:
            lines.append(f"ğŸ’” <b>æœ€å·®</b>: {worst['symbol']} {worst['day7_change']:.1f}%")
        lines.append("")
        
        # è¿‡æ‹Ÿåˆè­¦å‘Š
        overfitting = analysis.get('overfitting_analysis', {})
        if overfitting.get('concerns'):
            lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            lines.append("âš ï¸ <b>é£é™©æç¤º</b>")
            for concern in overfitting['concerns'][:3]:
                lines.append(f"â€¢ {concern}")
            lines.append("")
        
        # æ¨¡å‹è°ƒæ•´
        if adjustments and adjustments.get('applied'):
            lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            lines.append("ğŸ”§ <b>æ¨¡å‹å·²è‡ªåŠ¨è°ƒæ•´</b>")
            for adj in adjustments['applied'][:5]:
                lines.append(f"â€¢ {adj['param']}: {adj['old']} â†’ {adj['new']}")
            lines.append("")
        
        return "\n".join(lines)
    
    def format_analysis_report(self, analysis: Dict, adjustments: Dict = None) -> str:
        """ç”Ÿæˆå®Œæ•´åˆ†ææŠ¥å‘Š"""
        lines = [
            "=" * 70,
            f"ğŸ“Š æ¯å‘¨åˆ†ææŠ¥å‘Š",
            f"åˆ†æå‘¨æœŸ: {analysis['week_start']} è‡³ {analysis['week_end']}",
            "=" * 70,
            "",
            "ã€æ•´ä½“è¡¨ç°ã€‘",
            f"  æ€»ä¿¡å·æ•°: {analysis['total_signals']}",
            f"  æˆåŠŸä¿¡å·: {analysis['successful_signals']}",
            f"  å‡†ç¡®ç‡: {analysis['accuracy_rate']:.1f}%",
            f"  å¹³å‡æ”¶ç›Š: {analysis['avg_return']:.2f}%",
            f"  å¹³å‡æœ€å¤§æ¶¨å¹…: {analysis['avg_max_gain']:.2f}%",
            f"  å¹³å‡æœ€å¤§è·Œå¹…: {analysis['avg_max_loss']:.2f}%",
            ""
        ]
        
        lines.append("ã€æŒ‰è¯„åˆ†åˆ†ç»„ã€‘")
        for group, data in analysis.get('by_score', {}).items():
            group_name = {'high': 'é«˜åˆ†(â‰¥70)', 'medium': 'ä¸­åˆ†(40-69)', 'low': 'ä½åˆ†(<40)'}.get(group, group)
            lines.append(f"  {group_name}: {data['total']}ä¸ª, å‡†ç¡®ç‡ {data['accuracy']:.1f}%, å¹³å‡æ”¶ç›Š {data['avg_return']:.2f}%")
        lines.append("")
        
        lines.append("ã€å„ç±»ä¿¡å·è¡¨ç°ã€‘")
        for signal, perf in sorted(analysis.get('signal_performance', {}).items(), 
                                   key=lambda x: x[1]['accuracy'], reverse=True):
            lines.append(f"  {signal}: {perf['count']}æ¬¡, å‡†ç¡®ç‡ {perf['accuracy']:.1f}%, å¹³å‡æ”¶ç›Š {perf['avg_return']:.2f}%")
        lines.append("")
        
        best = analysis.get('best_performer')
        worst = analysis.get('worst_performer')
        if best:
            lines.append(f"ã€æœ€ä½³è¡¨ç°ã€‘{best['symbol']} ({best['name']})")
            lines.append(f"  ä¿¡å·è¯„åˆ†: {best['score']}, 7æ—¥æ”¶ç›Š: {best['day7_change']:.2f}%")
        if worst:
            lines.append(f"ã€æœ€å·®è¡¨ç°ã€‘{worst['symbol']} ({worst['name']})")
            lines.append(f"  ä¿¡å·è¯„åˆ†: {worst['score']}, 7æ—¥æ”¶ç›Š: {worst['day7_change']:.2f}%")
        lines.append("")
        
        overfitting = analysis.get('overfitting_analysis', {})
        if overfitting.get('concerns'):
            lines.append("ã€âš ï¸ é£é™©æç¤ºã€‘")
            for concern in overfitting['concerns']:
                lines.append(f"  â€¢ {concern}")
            lines.append("")
        
        suggestions = analysis.get('optimization_suggestions', [])
        if suggestions:
            lines.append("ã€ä¼˜åŒ–å»ºè®®ã€‘")
            for i, sug in enumerate(suggestions, 1):
                priority_icon = {'high': 'ğŸ”´', 'medium': 'ğŸŸ¡', 'low': 'ğŸŸ¢'}.get(sug['priority'], 'âšª')
                lines.append(f"  {i}. {priority_icon} {sug['action']}")
                lines.append(f"     åŸå› : {sug['reason']}")
            lines.append("")
        
        if adjustments:
            if adjustments.get('applied'):
                lines.append("ã€å·²åº”ç”¨çš„æ¨¡å‹è°ƒæ•´ã€‘")
                for adj in adjustments['applied']:
                    lines.append(f"  â€¢ {adj['param']}: {adj['old']} â†’ {adj['new']}")
                lines.append("")
            
            if adjustments.get('skipped'):
                lines.append("ã€éœ€äººå·¥å¤„ç†ã€‘")
                for skip in adjustments['skipped']:
                    lines.append(f"  â€¢ {skip['suggestion']}")
                lines.append("")
        
        lines.extend([
            "=" * 70,
            f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "=" * 70
        ])
        
        return "\n".join(lines)
    
    def send_telegram(self, analysis: Dict, adjustments: Dict = None) -> bool:
        """å‘é€Telegramé€šçŸ¥"""
        tg_config = self.config.get('notification', {}).get('telegram', {})
        
        if not tg_config.get('enabled') or not tg_config.get('bot_token'):
            logger.info("Telegramé€šçŸ¥æœªå¯ç”¨")
            return False
        
        notifier = TelegramNotifier(tg_config['bot_token'], tg_config['chat_id'])
        message = self.format_telegram_message(analysis, adjustments)
        return notifier.send_message(message)
    
    def run(self, auto_optimize: bool = True):
        """è¿è¡Œæ¯å‘¨åˆ†æ"""
        logger.info("å¼€å§‹æ¯å‘¨åˆ†æ...")
        
        # 1. æ›´æ–°è¿½è¸ªæ•°æ®
        self.update_tracking_data()
        
        # 2. åˆ†ææœ¬å‘¨è¡¨ç°
        analysis = self.analyze_week()
        
        # 3. è‡ªåŠ¨ä¼˜åŒ–æ¨¡å‹
        adjustments = {}
        if auto_optimize:
            adjustments = self.auto_optimize_model(analysis)
        
        # 4. ç”ŸæˆæŠ¥å‘Š
        report = self.format_analysis_report(analysis, adjustments)
        print(report)
        
        # 5. ä¿å­˜æŠ¥å‘Š
        report_dir = Path('/home/ubuntu/stock_screener/reports/weekly')
        report_dir.mkdir(parents=True, exist_ok=True)
        
        report_path = report_dir / f"weekly_analysis_{analysis['week_end']}.txt"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        logger.info(f"æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        # 6. å‘é€Telegramé€šçŸ¥
        self.send_telegram(analysis, adjustments)
        
        return analysis, adjustments


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='æ¯å‘¨åˆ†æå’Œæ¨¡å‹ä¼˜åŒ–')
    parser.add_argument('--no-optimize', action='store_true', help='ä¸è‡ªåŠ¨ä¼˜åŒ–æ¨¡å‹')
    parser.add_argument('--update-tracking', action='store_true', help='ä»…æ›´æ–°è¿½è¸ªæ•°æ®')
    
    args = parser.parse_args()
    
    analyzer = WeeklyAnalyzer()
    
    if args.update_tracking:
        analyzer.update_tracking_data()
    else:
        analyzer.run(auto_optimize=not args.no_optimize)


if __name__ == '__main__':
    main()
